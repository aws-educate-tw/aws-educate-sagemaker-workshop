{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff841a2-306b-4a09-a248-d6dc01b94ec5",
   "metadata": {},
   "source": [
    "_API Reference: https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#steps_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4581744-4b63-4dc9-b506-4c6ca9e6c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker transformers==4.44.2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4382b5-28fb-4434-a3c1-88bd6ad252b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TrainingStep, ProcessingStep, CreateModelStep, CacheConfig\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7ada8-41b9-4bfd-a5c7-0352a433bb2c",
   "metadata": {},
   "source": [
    "## 取得 Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21e08c-0e15-4188-84e3-17e5e85484fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# 初始化 S3 客戶端，來源區域是 ap-northeast-1，目標區域是 us-west-2\n",
    "s3_source = boto3.client('s3', region_name=\"us-west-2\")\n",
    "s3_target = boto3.client('s3', region_name=\"us-west-2\")\n",
    "\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "def copy_s3_object(source_uri, target_bucket):\n",
    "    source_bucket, source_key = parse_s3_uri(source_uri)\n",
    "    try:\n",
    "        # 從來源 bucket 下載檔案\n",
    "        response = s3_source.get_object(Bucket=source_bucket, Key=source_key)\n",
    "        file_content = response['Body'].read()\n",
    "\n",
    "        # 將檔案上傳到目標 bucket\n",
    "        s3_target.put_object(Bucket=target_bucket, Key=source_key, Body=file_content)\n",
    "        print(f\"Copied {source_key} to {target_bucket}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {source_key}: {str(e)}\")\n",
    "\n",
    "# s3 URI\n",
    "base_uri = 's3://aws-educate-09-28-sagemaker-workshop-oregon/datasets/phi-3.5-mini-instruct/workshop/'\n",
    "train_uri = base_uri + 'train_dataset.json'\n",
    "test_uri = base_uri + 'test_dataset.json'\n",
    "\n",
    "# 你的目標 S3 bucket\n",
    "target_bucket = sess.default_bucket()\n",
    "\n",
    "\n",
    "# 複製 train 和 test 資料到新的 S3 bucket\n",
    "copy_s3_object(train_uri, target_bucket)\n",
    "copy_s3_object(test_uri, target_bucket)\n",
    "\n",
    "datasets_s3_uri = \"s3://\" + target_bucket + \"/datasets/phi-3.5-mini-instruct/workshop/\"\n",
    "\n",
    "print(datasets_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723434b5-76d4-485b-9f0d-1c141f693231",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls 's3://sagemaker-us-west-2-539656205201/datasets/phi-3.5-mini-instruct/workshop/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828512d-0375-4104-b71c-9769f7f7b0a8",
   "metadata": {},
   "source": [
    "## Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fe262-89b9-4c0e-90a8-596cd554eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義參數\n",
    "training_datasets_s3_uri = ParameterString(name=\"TrainingDatasetesS3Uri\", default_value=datasets_s3_uri)\n",
    "\n",
    "\n",
    "# 其他配置\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"30d\")\n",
    "model_package_group_name = \"Practice-SageMaker-Pipeline-Group\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcaf85-e1ad-42a5-a4b8-2e337b9a30b6",
   "metadata": {},
   "source": [
    "## TraningStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfaa7a-5c79-47ae-99d9-05ce290e85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 3,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 2,                 # Number of updates steps to accumulate \n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'fp16': True ,\n",
    "  'learning_rate': 2e-4,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"constant\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run',                         # output directory, where to save assets during training\n",
    "}\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}'\n",
    "\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = '../scripts',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.p3.2xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    ")\n",
    "\n",
    "\n",
    "# 定義訓練步驟\n",
    "train_step = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=huggingface_estimator,\n",
    "    inputs={\n",
    "        'training': TrainingInput(training_datasets_s3_uri, content_type=\"application/json\")\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b536da2-8cfe-4f15-a132-e71fcba80a04",
   "metadata": {},
   "source": [
    "## Register Model Step\n",
    "Documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd3e52-9dac-4f51-885a-bf8dab1bd90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "config = {\n",
    "    'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "    'SM_NUM_GPUS': json.dumps(1), # Number of GPU used per replica\n",
    "    'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "    'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "model = HuggingFaceModel( # https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-model\n",
    "    model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts, # https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html\n",
    "    role=role,\n",
    "    image_uri=llm_image,\n",
    "    sagemaker_session=sess,\n",
    "    env=config\n",
    ")\n",
    "\n",
    "register_step = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    model=model,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.g4dn.xlarge\", \"ml.g5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829532f-15ed-42dc-853c-e4e7c9f4d2ac",
   "metadata": {},
   "source": [
    "## Lambda Step for Deploying model endpoint\n",
    "documents: \n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-lambda\n",
    "- https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65fb8e-a048-4019-8e30-e0475271ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lambda_deployer.py\n",
    "\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"Lambda function to deploy a model to an Endpoint using boto3\"\"\"\n",
    "\n",
    "    # 使用 event 中的參數\n",
    "    model_package_arn = event[\"model_package_arn\"]\n",
    "    model_name = event[\"model_name\"]\n",
    "    endpoint_config_name = event[\"endpoint_config_name\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    role = event[\"role\"]\n",
    "\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    # 創建模型\n",
    "    create_model_response = sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        PrimaryContainer={\"ModelPackageName\": model_package_arn},\n",
    "        ExecutionRoleArn=role,\n",
    "    )\n",
    "\n",
    "    # 創建端點配置\n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"InstanceType\": \"ml.g5.2xlarge\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"ModelName\": model_name,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # 創建端點\n",
    "    create_endpoint_response = sm_client.create_endpoint(\n",
    "        EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "    )\n",
    "\n",
    "    return {\"statusCode\": 200, \"body\": json.dumps(f\"Created Endpoint {endpoint_name}!\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe4780-fe3e-4279-9d10-a64cd1d56756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "def create_lambda_role(role_name):\n",
    "    try:\n",
    "        response = iam.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps({\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": \"lambda.amazonaws.com\"\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\"\n",
    "                    }\n",
    "                ]\n",
    "            }),\n",
    "            Description='Role for Lambda to use SageMaker Service'\n",
    "        )\n",
    "\n",
    "        role_arn = response['Role']['Arn']\n",
    "\n",
    "        response = iam.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "        )\n",
    "\n",
    "        response = iam.attach_role_policy(\n",
    "            PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "            RoleName=role_name\n",
    "        )\n",
    "\n",
    "        return role_arn\n",
    "\n",
    "    except iam.exceptions.EntityAlreadyExistsException:\n",
    "        print(f'Using ARN from existing role: {role_name}')\n",
    "        response = iam.get_role(RoleName=role_name)\n",
    "        return response['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b202ea-386c-42c4-b9fd-cb3763b36ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "\n",
    "lambda_role = create_lambda_role(\"lambda-deployment-for-prac-pipeline-role\") \n",
    "\n",
    "# Use the current time to define unique names for the resources created\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "model_name = \"practice-sagemaker-pipeline-model\" + current_time\n",
    "endpoint_name = \"practice-sagemaker-pipeline-endpoint-\" + current_time\n",
    "endpoint_config_name = \"practice-sagemaker-pipeline-endpoint-config\" + current_time\n",
    "function_name = \"practice-sagemaker-pipeline-lambda-step\" + current_time\n",
    "\n",
    "# Lambda helper class can be used to create the Lambda function\n",
    "func = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"lambda_deployer.py\",\n",
    "    handler=\"lambda_deployer.lambda_handler\",\n",
    "    timeout=600,\n",
    "    memory_size=10240,\n",
    ")\n",
    "\n",
    "# The dictionary retured by the Lambda function is captured by LambdaOutput, each key in the dictionary corresponds to a\n",
    "# LambdaOutput\n",
    "\n",
    "output_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "# The inputs provided to the Lambda function can be retrieved via the `event` object within the `lambda_handler` function\n",
    "# in the Lambda\n",
    "lambda_deploy_step = LambdaStep(\n",
    "    name=\"LambdaStepDeployModelEndpoint\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"model_package_arn\": register_step.properties.ModelPackageArn,\n",
    "        \"model_name\": model_name,\n",
    "        \"endpoint_config_name\": endpoint_config_name,\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"role\": role\n",
    "    },\n",
    "    outputs=[output_param_1, output_param_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e75618-de5a-4f05-9619-c48e06645c80",
   "metadata": {},
   "source": [
    "## Pipeline Definition\n",
    "\n",
    "API Reference: https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0a9ec-6593-42d2-976d-bf2f4b9847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 Pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=\"PracticeSageMakerPipeline\",\n",
    "    parameters=[training_datasets_s3_uri],\n",
    "    steps=[train_step, register_step, lambda_deploy_step]\n",
    ")\n",
    "\n",
    "# 創建(或更新) Pipeline\n",
    "pipeline.upsert(role_arn=role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f60306-5ec1-4fca-809b-d3ce7328b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 執行 Pipeline\n",
    "execution = pipeline.start(\n",
    "        parameters={\"TrainingDatasetesS3Uri\": datasets_s3_uri},\n",
    "        execution_display_name=\"Practice-ExecuteFromNotebook\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3ecca-c6c7-4779-87e4-291a4f7c45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得執行狀態\n",
    "execution.describe()\n",
    "\n",
    "# 等待 Pipeline 執行完成\n",
    "execution.wait()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
