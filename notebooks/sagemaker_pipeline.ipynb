{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff841a2-306b-4a09-a248-d6dc01b94ec5",
   "metadata": {},
   "source": [
    "_API Reference: https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#steps_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4581744-4b63-4dc9-b506-4c6ca9e6c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker transformers==4.44.2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4382b5-28fb-4434-a3c1-88bd6ad252b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TrainingStep, ProcessingStep, CreateModelStep, CacheConfig\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7ada8-41b9-4bfd-a5c7-0352a433bb2c",
   "metadata": {},
   "source": [
    "## 取得 Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21e08c-0e15-4188-84e3-17e5e85484fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# 初始化 S3 客戶端，來源區域是 ap-northeast-1，目標區域是 us-west-2\n",
    "s3_source = boto3.client('s3', region_name=\"ap-northeast-1\")\n",
    "s3_target = boto3.client('s3', region_name=\"us-west-2\")\n",
    "\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "def copy_s3_object(source_uri, target_bucket):\n",
    "    source_bucket, source_key = parse_s3_uri(source_uri)\n",
    "    try:\n",
    "        # 從來源 bucket 下載檔案\n",
    "        response = s3_source.get_object(Bucket=source_bucket, Key=source_key)\n",
    "        file_content = response['Body'].read()\n",
    "\n",
    "        # 將檔案上傳到目標 bucket\n",
    "        s3_target.put_object(Bucket=target_bucket, Key=source_key, Body=file_content)\n",
    "        print(f\"Copied {source_key} to {target_bucket}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {source_key}: {str(e)}\")\n",
    "\n",
    "# s3 URI\n",
    "base_uri = 's3://aws-educate-09-28-sagemaker-workshop/datasets/phi-3/'\n",
    "train_uri = base_uri + 'train_dataset.json'\n",
    "test_uri = base_uri + 'test_dataset.json'\n",
    "\n",
    "# 你的目標 S3 bucket\n",
    "target_bucket = sess.default_bucket()\n",
    "\n",
    "\n",
    "# 複製 train 和 test 資料到新的 S3 bucket\n",
    "copy_s3_object(train_uri, target_bucket)\n",
    "copy_s3_object(test_uri, target_bucket)\n",
    "\n",
    "datasets_s3_uri = \"s3://\" + target_bucket + \"/datasets/phi-3/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828512d-0375-4104-b71c-9769f7f7b0a8",
   "metadata": {},
   "source": [
    "## Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3fe262-89b9-4c0e-90a8-596cd554eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義參數\n",
    "training_datasets_s3_uri = ParameterString(name=\"TrainingDatasetesS3Uri\", default_value=datasets_s3_uri)\n",
    "model_package_group_name = \"Demo-SageMaker-Pipeline-Group\"\n",
    "\n",
    "# 其他配置\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"30d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcaf85-e1ad-42a5-a4b8-2e337b9a30b6",
   "metadata": {},
   "source": [
    "## TraningStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebfaa7a-5c79-47ae-99d9-05ce290e85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 3,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 2,                 # Number of updates steps to accumulate \n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'fp16': True ,\n",
    "  'learning_rate': 2e-4,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"constant\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run',                         # output directory, where to save assets during training\n",
    "}\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}'\n",
    "\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = '../scripts',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.p3.2xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    ")\n",
    "\n",
    "\n",
    "# 定義訓練步驟\n",
    "train_step = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=huggingface_estimator,\n",
    "    inputs={\n",
    "        'training': TrainingInput(training_datasets_s3_uri, content_type=\"application/json\")\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b536da2-8cfe-4f15-a132-e71fcba80a04",
   "metadata": {},
   "source": [
    "## Register Model Step\n",
    "Documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd3e52-9dac-4f51-885a-bf8dab1bd90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "config = {\n",
    "    'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "    'SM_NUM_GPUS': json.dumps(1), # Number of GPU used per replica\n",
    "    'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "    'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "model = HuggingFaceModel( # https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-model\n",
    "    model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts, # https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html\n",
    "    role=role,\n",
    "    image_uri=llm_image,\n",
    "    sagemaker_session=sess,\n",
    "    env=config\n",
    ")\n",
    "\n",
    "register_step = RegisterModel(\n",
    "    name=\"DemoSageMakerPipelineModel\",\n",
    "    model=model,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.g4dn.xlarge\", \"ml.g5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856636d5-0505-475f-bdaf-64067576b696",
   "metadata": {},
   "source": [
    "## Deploy Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "738020a0-9188-4481-87e8-51be0e1dd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.model import Model\n",
    "# from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "# from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# # retrieve the llm image uri\n",
    "# llm_image = get_huggingface_llm_image_uri(\n",
    "#   \"huggingface\",\n",
    "#   session=sess,\n",
    "# )\n",
    "\n",
    "# # print ecr image uri\n",
    "# print(f\"llm image uri: {llm_image}\")\n",
    "\n",
    "# # 創建模型\n",
    "# model = Model(\n",
    "#     image_uri=llm_image,\n",
    "#     model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#     role=role,\n",
    "#     sagemaker_session=PipelineSession()\n",
    "# )\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9e4e93b-5799-48f2-baea-bd2bb519f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "# # 定義模型部署步驟\n",
    "# deploy_step = ModelStep(\n",
    "#     name='ModelDeployment',\n",
    "#     step_args=model.create(instance_type=\"ml.m5.large\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e75618-de5a-4f05-9619-c48e06645c80",
   "metadata": {},
   "source": [
    "## Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0a9ec-6593-42d2-976d-bf2f4b9847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 Pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=\"TrainingAndRegisterPipeline\",\n",
    "    parameters=[training_datasets_s3_uri],\n",
    "    steps=[train_step, register_step]\n",
    ")\n",
    "\n",
    "# 開始執行 Pipeline\n",
    "pipeline.upsert(role_arn=role)\n",
    "# execution = pipeline.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bc3ecca-c6c7-4779-87e4-291a4f7c45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取得執行狀態\n",
    "# execution.describe()\n",
    "\n",
    "# # 等待 Pipeline 執行完成\n",
    "# execution.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf3cd2-02c7-439a-afc2-ba4b02b269e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb51bb6-5fcf-4192-af50-1f570151127b",
   "metadata": {},
   "source": [
    "## Manually Deploy a Model from the Registry\n",
    "Domumentation: https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-deploy.html#model-registry-deploy-smsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ae2c2-2530-4b7d-9240-8ac3181822e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage # https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.ModelPackage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_package_arn = \"arn:aws:sagemaker:us-west-2:097724924093:model-package/Demo-SageMaker-Pipeline-Group/3\"\n",
    "model = ModelPackage(role=role, # https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.ModelPackage\n",
    "                     model_package_arn=model_package_arn,\n",
    "                     sagemaker_session=sess)\n",
    "model.deploy(initial_instance_count=1, instance_type='ml.g5.xlarge', container_startup_health_check_timeout=1000) # https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
