{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cde7bb-cd21-40b5-bb46-83f0f3fabbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51fc789-3af3-4f22-8822-e1cc4f53418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TrainingStep, ProcessingStep, CreateModelStep, CacheConfig\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13405d1-de41-435f-bd92-f1b13bd54fd9",
   "metadata": {},
   "source": [
    "## Manually Deploy a Model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f0c6f-4f26-4a58-86ce-1a6bab8856e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# Model s3 uri \n",
    "model_artifact_s3_uri = \"s3://sagemaker-us-west-2-539656205201/huggingface-qlora-microsoft-Phi-3-5-min-2024-09-24-19-25-26-124/output/model.tar.gz\"\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "config = {\n",
    "    'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "    'SM_NUM_GPUS': json.dumps(1), # Number of GPU used per replica\n",
    "    'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "    'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "model = HuggingFaceModel( # https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-model\n",
    "    model_data=model_artifact_s3_uri,\n",
    "    image_uri=llm_image,\n",
    "    sagemaker_session=sess,\n",
    "    role=role,\n",
    "    env=config\n",
    ")\n",
    "\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.g5.4xlarge', container_startup_health_check_timeout=1000) # https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc66555f-7ebc-4415-b928-b7a78fe95ab8",
   "metadata": {},
   "source": [
    "## Manually Deploy a Model from S3 (uncompressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156f7b1-6035-4336-aa71-d8392afff2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.huggingface import HuggingFaceModel\n",
    "# from sagemaker.workflow.step_collections import RegisterModel\n",
    "# from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# # Model s3 prefix(folder) uri  \n",
    "# model_s3_prefix_uri = \"s3://sagemaker-us-west-2-097724924093/huggingface-qlora-microsoft-Phi-3-5-min-2024-09-11-04-03-17-319/output/model/\"\n",
    "\n",
    "# # retrieve the llm image uri\n",
    "# llm_image = get_huggingface_llm_image_uri(\n",
    "#   \"huggingface\",\n",
    "#   session=sess,\n",
    "# )\n",
    "\n",
    "# config = {\n",
    "#     'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "#     'SM_NUM_GPUS': json.dumps(1), # Number of GPU used per replica\n",
    "#     'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "#     'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "# }\n",
    "\n",
    "# model = HuggingFaceModel( # https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-model\n",
    "#     model_data={'S3DataSource':{'S3Uri': model_s3_prefix_uri,'S3DataType': 'S3Prefix','CompressionType': 'None'}}, # We use a dict, for more details, please refer to these two documents: https://sagemaker.readthedocs.io/en/stable/api/inference/model.html, https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3ModelDataSource.html\n",
    "#     role=role,\n",
    "#     image_uri=llm_image,\n",
    "#     sagemaker_session=sess,\n",
    "#     env=config\n",
    "# )\n",
    "\n",
    "\n",
    "# predictor = model.deploy(initial_instance_count=1, instance_type='ml.g5.2xlarge', container_startup_health_check_timeout=1000) # https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
