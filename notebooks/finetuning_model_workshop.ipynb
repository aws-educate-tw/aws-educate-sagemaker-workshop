{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train and Deploy open LLMs with Amazon SageMaker**\n",
    "\n",
    "⭐ <font color=orange>**由於今天工作坊的訓練與部署皆需要等待較久，為了節省各位的時間，會需要各位先按下 `Run All` 後，一邊等待程式碼執行一邊進行內容分享**</font>\n",
    "\n",
    "> ### **Jupyter Notebook 快速操作教學**\n",
    "> **Jupyter Notebook** 是一個基於網頁的開發環境，允許您在單一介面中編寫和執行程式碼、查看結果、撰寫筆記及進行數據可視化。它廣泛應用於數據科學、機器學習和學術研究。\n",
    "> - Jupyter Notebook 中的單元格分為三種類型:\n",
    ">   1. **Code**: 編寫 Python 程式碼的單元格，按 `Shift + Enter` 執行程式碼\n",
    ">   2. **Markdown**: 用於撰寫說明文字，支援 Markdown 語法，按 `Shift + Enter` 渲染文本\n",
    ">   3. **Raw**: 原始資料單元格，不會被處理\n",
    "> \n",
    "> - 對單元格進行操作:\n",
    ">   1. 編輯單元格: 按 `Enter` (本次工作坊不需使用)\n",
    ">   2. 執行單元格: 按 `Shift + Enter` / 按 `Run` 按鈕\n",
    ">\n",
    "> ### **⮕ <font style=\"color: black ;background: orange\">Shift + Enter</font> is all you need! (and <font style=\"color: black ;background: orange\">Run All</font>🤣)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **設置開發環境**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Hugging Face 簡介**\n",
    "\n",
    "Hugging Face 是一個開源平台，集成超過 47 萬個預先訓練的 AI 模型和資料集，使開發者可以快速存取、應用和微調這些模型，從而加速自然語言處理和 AI 應用的開發過程。Hugging Face 提供標準化的函式庫和 API，使模型的下載、整合和部署更加簡便和標準化。\n",
    "\n",
    "> - **由於時間因素，本次工作坊已將模型放上 S3，不會帶大家從 Hugging Face 上進行任何操作**，若今日活動後還想在自己的 Hugging Face 下載模型，請登入自己的帳號、產生 token、同意模型使用條款、並修改程式碼。   \n",
    "> \n",
    "> - 若想在地端環境使用 SageMaker，需要擁有具備 SageMaker 所需權限的 IAM role，更多資訊請參考 [\\[How to use SageMaker execution roles\\]](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **安裝 Hugging Face 所需的特定版本套件**\n",
    "\n",
    "1. `huggingface_hub`: 版本 `0.24.6`，用於與 Hugging Face 模型和資料庫互動，允許用戶上傳和下載預訓練的模型、共享和管理模型。\n",
    "\n",
    "2. `transformers`: 版本 `4.44.2`，是一個預訓練模型套件，適用於自然語言處理、計算機視覺及語音處理等任務。該套件包含 Transformer 和非 Transformer 模型，方便開發者使用各類深度學習模型。\n",
    "\n",
    "3. `datasets`: 版本 `2.21.0`，用於獲取和處理各種數據集，特別是在機器學習和 NLP 任務中使用的數據。\n",
    "\n",
    "4. `--quiet`: 讓安裝過程中的輸出介面保持整潔，不會印出過多的安裝細節。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For resolving version conflicts,  not mandatory\n",
    "!pip uninstall awscli --yes --quiet\n",
    "!pip install 'docutils>=0.18.1,<0.21' --quiet\n",
    "\n",
    "# Install the specific version of packages required by Hugging Face\n",
    "!pip install huggingface_hub==0.24.6 transformers==4.44.2 datasets==2.21.0 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **設定 SageMaker 環境並獲取相關的 AWS IAM 角色和 S3 bucket 資訊**\n",
    "\n",
    "1. **Boto3**: AWS 的 Python SDK，用於與 AWS 服務進行交互，包括創建和管理資源。\n",
    "\n",
    "2. **SageMaker Session**: 管理 SageMaker 的操作和資源，提供統合機器學習工作流的接口，確保操作一致且簡單。\n",
    "\n",
    "3. **Storage Bucket**: 用於存儲數據和模型的 S3 存儲桶。在此程式碼中，使用 `sess.default_bucket()` 獲取預設存儲桶。\n",
    "\n",
    "4. **Execution Role**: IAM 角色，授予 SageMaker 執行所需的權限，讓它可以訪問其他 AWS 資源（如 S3 存儲桶）。使用 `sagemaker.get_execution_role()` 獲取角色。\n",
    "\n",
    "    <img src=\"../imgs/d-sagemaker-env-setup.png\" width=\"850\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Creates a SageMaker session to manage operations related to SageMaker\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Setup SageMaker storage bucket:\n",
    "sagemaker_bucket=None\n",
    "if sagemaker_bucket is None and sess is not None:\n",
    "    sagemaker_bucket = sess.default_bucket()\n",
    "\n",
    "# Get execution role\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Recreates the SageMaker session using the previously obtained sagemaker_session_bucket\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **處理資料集**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此處會引入本工作坊預先準備好的 Dataset\n",
    "- 大使訓練版：10000+ 筆資料 ⮕ 由於時間過久，本次工作坊不予使用\n",
    "- 工作坊版本：16 筆資料 ⮕ 僅供體驗，訓練效果不佳請見諒\n",
    "\n",
    "  <img src=\"../imgs/d-datasets.png\" width=\"600\">\n",
    "\n",
    "> **Dataset 來源**\n",
    "> 1. 由大使人工發想使用者可能情境，並調用 GenAI 生成貓咪占卜師語氣的回覆\n",
    ">\n",
    "> 2. 使用 Amazon Bedrock API 調用 Claude 3.5 sonnet，藉提示工程中的 In-Context Learning (Few Shot) 技巧，依據既有內容生成上萬筆資料，用於 Dataset   \n",
    "> \n",
    ">   - <img src=\"../imgs/d-generate-dataset.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **將本次工作坊提供的 Dataset 載入 SageMaker bucket**\n",
    "\n",
    "1. **Dataset 存放位置**: \n",
    "   - 大使的 bucket (source): `aws-educate-09-28-sagemaker-workshop-oregon/`\n",
    "     - 全部資料檔案: `/datasets/phi-3.5-mini-instruct/workshop/data.json`\n",
    "     - 訓練資料檔案: `/datasets/phi-3.5-mini-instruct/workshop/train_dataset.json`\n",
    "     - 測試資料檔案: `/datasets/phi-3.5-mini-instruct/workshop/test_dataset.json`\n",
    "   - SageMaker 的 bucket (destination): `sagemaker_bucket` (已在前一步驟用 `sess.default_bucket()` 獲取)\n",
    "    \n",
    "      <img src=\"../imgs/d-copy-dataset.png\" width=\"600\">\n",
    "  \n",
    "\n",
    "2. **解析 S3 URI**：\n",
    "   - `parse_s3_uri` 函數用來解析 S3 URI，從中提取 bucket name 和 key。\n",
    "\n",
    "3. **複製 S3 物件**：\n",
    "   - `copy_s3_object` 函數實現了從一個 S3 桶複製物件到另一個桶的邏輯。它使用 `get_object` 方法下載來源物件，然後使用 `put_object` 方法上傳到目標桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3', region_name=\"us-west-2\")\n",
    "\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def copy_s3_object(source_uri, target_bucket):\n",
    "    source_bucket, source_key = parse_s3_uri(source_uri)\n",
    "    try:\n",
    "        # Download file from source bucket\n",
    "        response = s3.get_object(Bucket=source_bucket, Key=source_key)\n",
    "        file_content = response['Body'].read()\n",
    "\n",
    "        # Upload file to target bucket\n",
    "        s3.put_object(Bucket=target_bucket,\n",
    "                             Key=source_key, Body=file_content)\n",
    "        print(f\"Successfully copied {source_key} to {target_bucket}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {source_key}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Base S3 URI for datasets\n",
    "amb_bucket = 's3://aws-educate-09-28-sagemaker-workshop-oregon'\n",
    "\n",
    "amb_train_uri = f\"{amb_bucket}/datasets/phi-3.5-mini-instruct/workshop/train_dataset.json\"\n",
    "amb_test_uri = f\"{amb_bucket}/datasets/phi-3.5-mini-instruct/workshop/test_dataset.json\"\n",
    "amb_data_uri = f\"{amb_bucket}/datasets/phi-3.5-mini-instruct/workshop/data.json\"\n",
    "\n",
    "# Copy train and test datasets to the target S3 bucket\n",
    "copy_s3_object(amb_train_uri, sagemaker_bucket)\n",
    "copy_s3_object(amb_test_uri, sagemaker_bucket)\n",
    "copy_s3_object(amb_data_uri, sagemaker_bucket)\n",
    "\n",
    "# Construct the S3 URI for the datasets in the target bucket\n",
    "sagemaker_datasets_uri = f\"s3://{sagemaker_bucket}/datasets/phi-3.5-mini-instruct/workshop/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **從 SageMaker bucket 查看 Dataset 的 Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import boto3\n",
    "\n",
    "def read_and_format_json_from_s3(uri):\n",
    "    bucket, key = parse_s3_uri(uri)\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "        file_content = obj['Body'].read().decode('utf-8')\n",
    "        \n",
    "        # parse json\n",
    "        try:\n",
    "            data = json.loads(file_content)\n",
    "        except json.JSONDecodeError:\n",
    "            data = []\n",
    "            for line in file_content.splitlines():\n",
    "                try:\n",
    "                    item = json.loads(line)\n",
    "                    data.append(item)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "\n",
    "        formatted_data = []\n",
    "        for item in data:\n",
    "            formatted_item = {}\n",
    "            if 'messages' in item:\n",
    "                formatted_item['input'] = item['messages'][0]['content']\n",
    "                formatted_item['output'] = item['messages'][1]['content']\n",
    "            else:\n",
    "                formatted_item = item\n",
    "            formatted_data.append(formatted_item)\n",
    "\n",
    "        return formatted_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading from S3: {e}\")\n",
    "        return None\n",
    "\n",
    "# s3 URI\n",
    "sagemaker_train_uri = sagemaker_datasets_uri + 'train_dataset.json'\n",
    "sagemaker_test_uri = sagemaker_datasets_uri + 'test_dataset.json'\n",
    "\n",
    "# Load and format training and test data from S3\n",
    "sagemaker_train_data = read_and_format_json_from_s3(sagemaker_train_uri)\n",
    "sagemaker_test_data = read_and_format_json_from_s3(sagemaker_test_uri)\n",
    "\n",
    "# Create DatasetDict from the formatted data\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(pd.DataFrame(sagemaker_train_data)),\n",
    "    'test': Dataset.from_pandas(pd.DataFrame(sagemaker_test_data))\n",
    "})\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(dataset)\n",
    "\n",
    "# Dataset Features\n",
    "print(\"\\n Dataset Features:\")\n",
    "print(dataset['train'].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#### **從 SageMaker 中查看 data.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def read_and_display_s3_data(s3_uri, limit=3):\n",
    "    # Parse the S3 URI into bucket and key\n",
    "    bucket, key = parse_s3_uri(s3_uri)\n",
    "\n",
    "    try:\n",
    "        # Retrieve the object from S3\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "        # Read and decode the data\n",
    "        data = response['Body'].read().decode('utf-8')\n",
    "\n",
    "        # Parse the JSON data\n",
    "        json_data = json.loads(data)\n",
    "\n",
    "        # Display a limited number of conversations\n",
    "        for idx, item in enumerate(json_data[:limit], 1):\n",
    "            print(f\"\\nConversation {idx}:\")\n",
    "            for message in item.get('messages', []):\n",
    "                role = message.get('role', 'unknown').capitalize()\n",
    "                content = message.get('content', 'No content')\n",
    "                print(f\"  {role}: {content}\")\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"Error reading S3 data: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON data: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sagemaker_data_uri = sagemaker_datasets_uri + 'data.json'\n",
    "read_and_display_s3_data(sagemaker_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀<font color=orange>**Now, lets Fine-tune our model. 🚀**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **進行 Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這個部分，我們將深入探討神經網絡的一些基本原理，以及如何通過調整超參數來優化模型訓練。我也會介紹 QLoRA（Quantization-aware Low-Rank Adaptation）的基本原理。\n",
    "\n",
    "首先，讓我們回顧一些關鍵概念：\n",
    "\n",
    "\n",
    "#### 神經網絡基礎概念(Neural Network Fundamentals)\n",
    "\n",
    "1. **神經網絡**\n",
    "   - 模仿人腦結構的機器學習模型\n",
    "   - 由多層神經元組成，通過權重(weight)和激活函數(activation function)處理輸入數據\n",
    "   - 廣泛應用於圖像識別(image recognition)、自然語言處理(NLP)、語音識別(speech recognition)等領域\n",
    "\n",
    "2. **前向傳播 (Forward Propagation)**\n",
    "   - 數據從輸入層(input layer)通過隱藏層(hidden layer)到輸出層(output layer)的過程\n",
    "   - 每一層的輸出(output)作為下一層的輸入(input)\n",
    "\n",
    "3. **反向傳播 (Backward Propagation)**\n",
    "   - 計算損失函數(loss function)對每個權重(weight)的梯度(gradient)\n",
    "   - 從輸出層(output layer)向輸入層(input layer)逐層調整權重(weight)\n",
    "\n",
    "4. **梯度下降 (Gradient Descent)**\n",
    "   - 優化神經網絡的核心算法\n",
    "   - 通過沿梯度(gradient)的反方向(negative direction)調整權重(weight)來最小化損失函數(loss function)\n",
    "\n",
    "#### 關鍵超參數(Hyperparameter)\n",
    "\n",
    "5. **批量大小 (Batch Size)**\n",
    "   - 每次更新權重時使用的訓練樣本數\n",
    "   - 較大的批量可以提高訓練穩定性，但可能需要更多內存\n",
    "\n",
    "6. **學習率 (Learning Rate)**\n",
    "   - 控制每次迭代(iteration)時權重調整的幅度\n",
    "   - 太大可能導致不收斂，太小可能導致訓練過慢\n",
    "\n",
    "#### 高級技術(Advanced Techniques)\n",
    "\n",
    "7. **量化 (Quantization)**\n",
    "   - 將模型參數從高精度轉換為低精度\n",
    "   - 可以減少模型大小和推理時間，但可能略微降低精度\n",
    "\n",
    "8. **LoRA (Low-Rank Adaptation)**\n",
    "   - 一種高效的模型微調技術\n",
    "   - 主要參數：\n",
    "     - alpha: 控制LoRA更新的強度\n",
    "     - rank: 決定適配器矩陣的秩，影響模型表達能力和計算成本\n",
    "\n",
    "   - 線性代數中的 rank 概念：\n",
    "     - 在大型神經網絡中，權重更新通常涉及高維矩陣\n",
    "     - LoRA 假設這些更新可以用低秩矩陣(low rank)來近似，從而減少訓練參數數量\n",
    "     - 通過調整 rank 參數，可以在模型複雜度和計算效率之間取得平衡\n",
    "\n",
    "9. **QLoRA (Quantization-aware Low-Rank Adaptation)**\n",
    "   - 結合量化和 LoRA 的技術\n",
    "   - 優化步驟：\n",
    "     1. 將預訓練模型量化後並凍結\n",
    "     2. 添加小型、可訓練的 LoRA 適配器層\n",
    "     3. 僅微調適配器層，同時使用凍結的量化模型作為上下文\n",
    "   - 優點：大大減少內存需求，同時保持模型性能\n",
    "\n",
    "這些超參數和技術在訓練腳本 [run_qlora.py](../scripts/run_qlora.py) 中被使用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': \"microsoft/Phi-3.5-mini-instruct\",    # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 3,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 2,                 # Number of updates steps to accumulate \n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'fp16': True ,\n",
    "  'learning_rate': 2e-4,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"constant\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run',                         # output directory, where to save assets during training\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **設置訓練任務**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = '../scripts',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.p3.2xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **設定訓練數據的位置，並啟動 Hugging Face 模型的訓練任務**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a data input dictionary with the uploaded S3 URIs\n",
    "data = {\n",
    "    'training': f\"s3://{sess.default_bucket()}/datasets/phi-3.5-mini-instruct/workshop\"\n",
    "}\n",
    "\n",
    "# Start the training job using the provided datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **將 S3 的 URI 轉換為一個可以直接在 AWS S3 管理控制台中訪問的 URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.model_data.replace(\"s3://\", \"https://s3.console.aws.amazon.com/s3/buckets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 🚀<font color=orange>**Now, lets deploy our model to an endpoint. 🚀**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 部署模型\n",
    "\n",
    "在前面訓練好模型之後，我們可以從 **SageMaker > Training > Training Job** 裡面找到 Model 的 S3 路徑，但在我們這個 Notebook 中，可以從 `huggingface_estimator.model_data` 取得 Model Artifact 的 S3 URI。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  # version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(huggingface_estimator.model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們現在可以使用容器 URI 和模型在 S3 的路徑來創建一個 `HuggingFaceModel`。同時，我們還需要設定 TGI（Text Generation Inference）的配置，包括 GPU 的數量和最大輸入 tokens。你可以在[這裡](https://huggingface.co/docs/text-generation-inference/basic_tutorials/launcher)找到完整的配置選項列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time, add the s3 path here\n",
    "model_s3_path = huggingface_estimator.model_data\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 600 # 10 minutes to be able to load the model\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data=model_s3_path,\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example request body\n",
    "data = {\n",
    "   \"inputs\": \"<|system|>\\n你是一隻具備科技知識且幽默的小貓咪 AWS 占卜師，風格親切可愛，會使用喵語表達，並常用 AWS 雲端技術來比喻日常生活中的情況。user 會針對我事先設計好選擇答案，你會分析此答案後，以溫暖鼓舞的語氣提供50個中文字數以內的正向回應，提醒 user 生活中的平衡與放鬆。你還會使用下列顏文字來增添表達的可愛感：(＝^ω^＝), (=①ω①=), (=ＴェＴ=), (=ↀωↀ=), (=ΦωΦ=), (ΦзΦ), (^・ω・^ ), (ฅ^•ﻌ•^ฅ)。<|end|>\\n<|user|>\\n團隊中的數據管理專家，能夠記住並快速檢索大量的數據和訊息，確保團隊在需要時能夠立即獲得所需的資料。你非常可靠，無論是文件、報告、還是歷史數據，都能夠完好無損地保存並準確地提供。<|end|>\\n<|assistant|>\\n喵哈哈！你這不就是活生生的S3嗎？(=^ω^=) 存儲海量數據還能快速檢索，簡直就是團隊的數據寶庫喵！不過可別忘了給自己設置個生命週期規則，把一些過時的記憶「歸檔」到腦袋的Glacier Deep Archive裡喵～這樣才能保持高效運轉喔！你的可靠程度，恐怕連99.999999999%的耐用性都比不上呢，真是太厲害了喵～<|end|><|assistant|>\"\n",
    "}\n",
    "\n",
    "# Inference request\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "當我們測試完之後，記得清理資源，避免衍生費用。\n",
    "(若需要使用請記得解除註解)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_model()\n",
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
