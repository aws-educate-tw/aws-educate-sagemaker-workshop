{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train and Deploy open LLMs with Amazon SageMaker**\n",
    "\n",
    "â­ <font color=orange>**ç”±æ–¼ä»Šå¤©å·¥ä½œåŠçš„è¨“ç·´èˆ‡éƒ¨ç½²çš†éœ€è¦ç­‰å¾…è¼ƒä¹…ï¼Œç‚ºäº†ç¯€çœå„ä½çš„æ™‚é–“ï¼Œæœƒéœ€è¦å„ä½å…ˆæŒ‰ä¸‹ `Run All` å¾Œï¼Œä¸€é‚Šç­‰å¾…ç¨‹å¼ç¢¼åŸ·è¡Œä¸€é‚Šé€²è¡Œå…§å®¹åˆ†äº«**</font>\n",
    "\n",
    "> ### **Jupyter Notebook å¿«é€Ÿæ“ä½œæ•™å­¸**\n",
    "> **Jupyter Notebook** æ˜¯ä¸€å€‹åŸºæ–¼ç¶²é çš„é–‹ç™¼ç’°å¢ƒï¼Œå…è¨±æ‚¨åœ¨å–®ä¸€ä»‹é¢ä¸­ç·¨å¯«å’ŒåŸ·è¡Œç¨‹å¼ç¢¼ã€æŸ¥çœ‹çµæœã€æ’°å¯«ç­†è¨˜åŠé€²è¡Œæ•¸æ“šå¯è¦–åŒ–ã€‚å®ƒå»£æ³›æ‡‰ç”¨æ–¼æ•¸æ“šç§‘å­¸ã€æ©Ÿå™¨å­¸ç¿’å’Œå­¸è¡“ç ”ç©¶ã€‚\n",
    "> - Jupyter Notebook ä¸­çš„å–®å…ƒæ ¼åˆ†ç‚ºä¸‰ç¨®é¡å‹:\n",
    ">   1. **Code**: ç·¨å¯« Python ç¨‹å¼ç¢¼çš„å–®å…ƒæ ¼ï¼ŒæŒ‰ `Shift + Enter` åŸ·è¡Œç¨‹å¼ç¢¼\n",
    ">   2. **Markdown**: ç”¨æ–¼æ’°å¯«èªªæ˜æ–‡å­—ï¼Œæ”¯æ´ Markdown èªæ³•ï¼ŒæŒ‰ `Shift + Enter` æ¸²æŸ“æ–‡æœ¬\n",
    ">   3. **Raw**: åŸå§‹è³‡æ–™å–®å…ƒæ ¼ï¼Œä¸æœƒè¢«è™•ç†\n",
    "> \n",
    "> - å°å–®å…ƒæ ¼é€²è¡Œæ“ä½œ:\n",
    ">   1. ç·¨è¼¯å–®å…ƒæ ¼: æŒ‰ `Enter` (æœ¬æ¬¡å·¥ä½œåŠä¸éœ€ä½¿ç”¨)\n",
    ">   2. åŸ·è¡Œå–®å…ƒæ ¼: æŒ‰ `Shift + Enter` / æŒ‰ `Run` æŒ‰éˆ•\n",
    ">\n",
    "> ### **â®• <font style=\"color: black ;background: orange\">Shift + Enter</font> is all you need! (and <font style=\"color: black ;background: orange\">Run All</font>ğŸ¤£)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **è¨­ç½®é–‹ç™¼ç’°å¢ƒ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Hugging Face ç°¡ä»‹**\n",
    "\n",
    "Hugging Face æ˜¯ä¸€å€‹é–‹æºå¹³å°ï¼Œé›†æˆè¶…é 47 è¬å€‹é å…ˆè¨“ç·´çš„ AI æ¨¡å‹å’Œè³‡æ–™é›†ï¼Œä½¿é–‹ç™¼è€…å¯ä»¥å¿«é€Ÿå­˜å–ã€æ‡‰ç”¨å’Œå¾®èª¿é€™äº›æ¨¡å‹ï¼Œå¾è€ŒåŠ é€Ÿè‡ªç„¶èªè¨€è™•ç†å’Œ AI æ‡‰ç”¨çš„é–‹ç™¼éç¨‹ã€‚Hugging Face æä¾›æ¨™æº–åŒ–çš„å‡½å¼åº«å’Œ APIï¼Œä½¿æ¨¡å‹çš„ä¸‹è¼‰ã€æ•´åˆå’Œéƒ¨ç½²æ›´åŠ ç°¡ä¾¿å’Œæ¨™æº–åŒ–ã€‚\n",
    "\n",
    "> - **ç”±æ–¼æ™‚é–“å› ç´ ï¼Œæœ¬æ¬¡å·¥ä½œåŠå·²å°‡æ¨¡å‹æ”¾ä¸Š S3ï¼Œä¸æœƒå¸¶å¤§å®¶å¾ Hugging Face ä¸Šé€²è¡Œä»»ä½•æ“ä½œ**ï¼Œè‹¥ä»Šæ—¥æ´»å‹•å¾Œé‚„æƒ³åœ¨è‡ªå·±çš„ Hugging Face ä¸‹è¼‰æ¨¡å‹ï¼Œè«‹ç™»å…¥è‡ªå·±çš„å¸³è™Ÿã€ç”¢ç”Ÿ tokenã€åŒæ„æ¨¡å‹ä½¿ç”¨æ¢æ¬¾ã€ä¸¦ä¿®æ”¹ç¨‹å¼ç¢¼ã€‚   \n",
    "> \n",
    "> - è‹¥æƒ³åœ¨åœ°ç«¯ç’°å¢ƒä½¿ç”¨ SageMakerï¼Œéœ€è¦æ“æœ‰å…·å‚™ SageMaker æ‰€éœ€æ¬Šé™çš„ IAM roleï¼Œæ›´å¤šè³‡è¨Šè«‹åƒè€ƒ [\\[How to use SageMaker execution roles\\]](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **å®‰è£ Hugging Face æ‰€éœ€çš„ç‰¹å®šç‰ˆæœ¬å¥—ä»¶**\n",
    "\n",
    "1. `huggingface_hub`: ç‰ˆæœ¬ `0.24.6`ï¼Œç”¨æ–¼èˆ‡ Hugging Face æ¨¡å‹å’Œè³‡æ–™åº«äº’å‹•ï¼Œå…è¨±ç”¨æˆ¶ä¸Šå‚³å’Œä¸‹è¼‰é è¨“ç·´çš„æ¨¡å‹ã€å…±äº«å’Œç®¡ç†æ¨¡å‹ã€‚\n",
    "\n",
    "2. `transformers`: ç‰ˆæœ¬ `4.44.2`ï¼Œæ˜¯ä¸€å€‹é è¨“ç·´æ¨¡å‹å¥—ä»¶ï¼Œé©ç”¨æ–¼è‡ªç„¶èªè¨€è™•ç†ã€è¨ˆç®—æ©Ÿè¦–è¦ºåŠèªéŸ³è™•ç†ç­‰ä»»å‹™ã€‚è©²å¥—ä»¶åŒ…å« Transformer å’Œé Transformer æ¨¡å‹ï¼Œæ–¹ä¾¿é–‹ç™¼è€…ä½¿ç”¨å„é¡æ·±åº¦å­¸ç¿’æ¨¡å‹ã€‚\n",
    "\n",
    "3. `datasets`: ç‰ˆæœ¬ `2.21.0`ï¼Œç”¨æ–¼ç²å–å’Œè™•ç†å„ç¨®æ•¸æ“šé›†ï¼Œç‰¹åˆ¥æ˜¯åœ¨æ©Ÿå™¨å­¸ç¿’å’Œ NLP ä»»å‹™ä¸­ä½¿ç”¨çš„æ•¸æ“šã€‚\n",
    "\n",
    "4. `--quiet`: è®“å®‰è£éç¨‹ä¸­çš„è¼¸å‡ºä»‹é¢ä¿æŒæ•´æ½”ï¼Œä¸æœƒå°å‡ºéå¤šçš„å®‰è£ç´°ç¯€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For resolving version conflicts,  not mandatory\n",
    "!pip uninstall awscli --yes --quiet\n",
    "!pip install 'docutils>=0.18.1,<0.21' --quiet\n",
    "\n",
    "# Install the specific version of packages required by Hugging Face\n",
    "!pip install huggingface_hub==0.24.6 transformers==4.44.2 datasets==2.21.0 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **è¨­å®š SageMaker ç’°å¢ƒä¸¦ç²å–ç›¸é—œçš„ AWS IAM è§’è‰²å’Œ S3 bucket è³‡è¨Š**\n",
    "\n",
    "1. **Boto3**: AWS çš„ Python SDKï¼Œç”¨æ–¼èˆ‡ AWS æœå‹™é€²è¡Œäº¤äº’ï¼ŒåŒ…æ‹¬å‰µå»ºå’Œç®¡ç†è³‡æºã€‚\n",
    "\n",
    "2. **SageMaker Session**: ç®¡ç† SageMaker çš„æ“ä½œå’Œè³‡æºï¼Œæä¾›çµ±åˆæ©Ÿå™¨å­¸ç¿’å·¥ä½œæµçš„æ¥å£ï¼Œç¢ºä¿æ“ä½œä¸€è‡´ä¸”ç°¡å–®ã€‚\n",
    "\n",
    "3. **Storage Bucket**: ç”¨æ–¼å­˜å„²æ•¸æ“šå’Œæ¨¡å‹çš„ S3 å­˜å„²æ¡¶ã€‚åœ¨æ­¤ç¨‹å¼ç¢¼ä¸­ï¼Œä½¿ç”¨ `sess.default_bucket()` ç²å–é è¨­å­˜å„²æ¡¶ã€‚\n",
    "\n",
    "4. **Execution Role**: IAM è§’è‰²ï¼Œæˆäºˆ SageMaker åŸ·è¡Œæ‰€éœ€çš„æ¬Šé™ï¼Œè®“å®ƒå¯ä»¥è¨ªå•å…¶ä»– AWS è³‡æºï¼ˆå¦‚ S3 å­˜å„²æ¡¶ï¼‰ã€‚ä½¿ç”¨ `sagemaker.get_execution_role()` ç²å–è§’è‰²ã€‚\n",
    "\n",
    "    <img src=\"../imgs/d-sagemaker-env-setup.png\" width=\"850\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Creates a SageMaker session to manage operations related to SageMaker\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Setup SageMaker storage bucket:\n",
    "sagemaker_bucket=None\n",
    "if sagemaker_bucket is None and sess is not None:\n",
    "    sagemaker_bucket = sess.default_bucket()\n",
    "\n",
    "# Get execution role\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Recreates the SageMaker session using the previously obtained sagemaker_session_bucket\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **è™•ç†è³‡æ–™é›†**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­¤è™•æœƒå¼•å…¥æœ¬å·¥ä½œåŠé å…ˆæº–å‚™å¥½çš„ Dataset\n",
    "- å¤§ä½¿è¨“ç·´ç‰ˆï¼š10000+ ç­†è³‡æ–™ â®• ç”±æ–¼æ™‚é–“éä¹…ï¼Œæœ¬æ¬¡å·¥ä½œåŠä¸äºˆä½¿ç”¨\n",
    "- å·¥ä½œåŠç‰ˆæœ¬ï¼š16 ç­†è³‡æ–™ â®• åƒ…ä¾›é«”é©—ï¼Œè¨“ç·´æ•ˆæœä¸ä½³è«‹è¦‹è«’\n",
    "\n",
    "  <img src=\"../imgs/d-datasets.png\" width=\"600\">\n",
    "\n",
    "> **Dataset ä¾†æº**\n",
    "> 1. ç”±å¤§ä½¿äººå·¥ç™¼æƒ³ä½¿ç”¨è€…å¯èƒ½æƒ…å¢ƒï¼Œä¸¦èª¿ç”¨ GenAI ç”Ÿæˆè²“å’ªå åœå¸«èªæ°£çš„å›è¦†\n",
    ">\n",
    "> 2. ä½¿ç”¨ Amazon Bedrock API èª¿ç”¨ Claude 3.5 sonnetï¼Œè—‰æç¤ºå·¥ç¨‹ä¸­çš„ In-Context Learning (Few Shot) æŠ€å·§ï¼Œä¾æ“šæ—¢æœ‰å…§å®¹ç”Ÿæˆä¸Šè¬ç­†è³‡æ–™ï¼Œç”¨æ–¼ Dataset   \n",
    "> \n",
    ">   - <img src=\"../imgs/d-generate-dataset.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **å°‡æœ¬æ¬¡å·¥ä½œåŠæä¾›çš„ Dataset è¼‰å…¥ SageMaker bucket**\n",
    "\n",
    "1. **Dataset å­˜æ”¾ä½ç½®**: \n",
    "   - å¤§ä½¿çš„ bucket (source): `aws-educate-09-28-sagemaker-workshop-oregon/`\n",
    "     - å…¨éƒ¨è³‡æ–™æª”æ¡ˆ: `/datasets/phi-3.5-mini-instruct/workshop/data.json`\n",
    "     - è¨“ç·´è³‡æ–™æª”æ¡ˆ: `/datasets/phi-3.5-mini-instruct/workshop/train_dataset.json`\n",
    "     - æ¸¬è©¦è³‡æ–™æª”æ¡ˆ: `/datasets/phi-3.5-mini-instruct/workshop/test_dataset.json`\n",
    "   - SageMaker çš„ bucket (destination): `sagemaker_bucket` (å·²åœ¨å‰ä¸€æ­¥é©Ÿç”¨ `sess.default_bucket()` ç²å–)\n",
    "    \n",
    "      <img src=\"../imgs/d-copy-dataset.png\" width=\"600\">\n",
    "  \n",
    "\n",
    "2. **è§£æ S3 URI**ï¼š\n",
    "   - `parse_s3_uri` å‡½æ•¸ç”¨ä¾†è§£æ S3 URIï¼Œå¾ä¸­æå– bucket name å’Œ keyã€‚\n",
    "\n",
    "3. **è¤‡è£½ S3 ç‰©ä»¶**ï¼š\n",
    "   - `copy_s3_object` å‡½æ•¸å¯¦ç¾äº†å¾ä¸€å€‹ S3 æ¡¶è¤‡è£½ç‰©ä»¶åˆ°å¦ä¸€å€‹æ¡¶çš„é‚è¼¯ã€‚å®ƒä½¿ç”¨ `get_object` æ–¹æ³•ä¸‹è¼‰ä¾†æºç‰©ä»¶ï¼Œç„¶å¾Œä½¿ç”¨ `put_object` æ–¹æ³•ä¸Šå‚³åˆ°ç›®æ¨™æ¡¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3', region_name=\"us-west-2\")\n",
    "\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def copy_s3_object(source_uri, target_bucket):\n",
    "    source_bucket, source_key = parse_s3_uri(source_uri)\n",
    "    try:\n",
    "        # Download file from source bucket\n",
    "        response = s3.get_object(Bucket=source_bucket, Key=source_key)\n",
    "        file_content = response['Body'].read()\n",
    "\n",
    "        # Upload file to target bucket\n",
    "        s3.put_object(Bucket=target_bucket,\n",
    "                             Key=source_key, Body=file_content)\n",
    "        print(f\"Successfully copied {source_key} to {target_bucket}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {source_key}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Base S3 URI for datasets\n",
    "amb_bucket = 's3://aws-educate-09-28-sagemaker-workshop-oregon'\n",
    "\n",
    "amb_train_uri = f\"{amb_bucket}/datasets/phi-3.5-mini-instruct/workshop/train_dataset.json\"\n",
    "amb_test_uri = f\"{amb_bucket}/datasets/phi-3.5-mini-instruct/workshop/test_dataset.json\"\n",
    "amb_data_uri = f\"{amb_bucket}/datasets/phi-3.5-mini-instruct/workshop/data.json\"\n",
    "\n",
    "# Copy train and test datasets to the target S3 bucket\n",
    "copy_s3_object(amb_train_uri, sagemaker_bucket)\n",
    "copy_s3_object(amb_test_uri, sagemaker_bucket)\n",
    "copy_s3_object(amb_data_uri, sagemaker_bucket)\n",
    "\n",
    "# Construct the S3 URI for the datasets in the target bucket\n",
    "sagemaker_datasets_uri = f\"s3://{\n",
    "    sagemaker_bucket}/datasets/phi-3.5-mini-instruct/workshop/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **å¾ SageMaker bucket æŸ¥çœ‹ Dataset çš„ Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import boto3\n",
    "\n",
    "def read_and_format_json_from_s3(uri):\n",
    "    bucket, key = parse_s3_uri(uri)\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "        file_content = obj['Body'].read().decode('utf-8')\n",
    "        \n",
    "        # parse json\n",
    "        try:\n",
    "            data = json.loads(file_content)\n",
    "        except json.JSONDecodeError:\n",
    "            data = []\n",
    "            for line in file_content.splitlines():\n",
    "                try:\n",
    "                    item = json.loads(line)\n",
    "                    data.append(item)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "\n",
    "        formatted_data = []\n",
    "        for item in data:\n",
    "            formatted_item = {}\n",
    "            if 'messages' in item:\n",
    "                formatted_item['input'] = item['messages'][0]['content']\n",
    "                formatted_item['output'] = item['messages'][1]['content']\n",
    "            else:\n",
    "                formatted_item = item\n",
    "            formatted_data.append(formatted_item)\n",
    "\n",
    "        return formatted_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading from S3: {e}\")\n",
    "        return None\n",
    "\n",
    "# s3 URI\n",
    "sagemaker_train_uri = sagemaker_datasets_uri + 'train_dataset.json'\n",
    "sagemaker_test_uri = sagemaker_datasets_uri + 'test_dataset.json'\n",
    "\n",
    "# Load and format training and test data from S3\n",
    "sagemaker_train_data = read_and_format_json_from_s3(sagemaker_train_uri)\n",
    "sagemaker_test_data = read_and_format_json_from_s3(sagemaker_test_uri)\n",
    "\n",
    "# Create DatasetDict from the formatted data\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(pd.DataFrame(sagemaker_train_data)),\n",
    "    'test': Dataset.from_pandas(pd.DataFrame(sagemaker_test_data))\n",
    "})\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(dataset)\n",
    "\n",
    "# Dataset Features\n",
    "print(\"\\n Dataset Features:\")\n",
    "print(dataset['train'].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#### **å¾ SageMaker ä¸­å¯Ÿçœ‹ data.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def read_and_display_s3_data(s3_uri, limit=3):\n",
    "    # Parse the S3 URI into bucket and key\n",
    "    bucket, key = parse_s3_uri(s3_uri)\n",
    "\n",
    "    try:\n",
    "        # Retrieve the object from S3\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "        # Read and decode the data\n",
    "        data = response['Body'].read().decode('utf-8')\n",
    "\n",
    "        # Parse the JSON data\n",
    "        json_data = json.loads(data)\n",
    "\n",
    "        # Display a limited number of conversations\n",
    "        for idx, item in enumerate(json_data[:limit], 1):\n",
    "            print(f\"\\nConversation {idx}:\")\n",
    "            for message in item.get('messages', []):\n",
    "                role = message.get('role', 'unknown').capitalize()\n",
    "                content = message.get('content', 'No content')\n",
    "                print(f\"  {role}: {content}\")\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"Error reading S3 data: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON data: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sagemaker_data_uri = sagemaker_datasets_uri + 'data.json'\n",
    "read_and_display_s3_data(sagemaker_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **å°‡è¨“ç·´å’Œæ¸¬è©¦è³‡æ–™ä¿å­˜åˆ° SageMaker é è¨­è·¯å¾‘ä¸­**\n",
    "\n",
    "SageMaker é è¨­è·¯å¾‘ `/opt/ml/input/data/training` æ˜¯ SageMaker è‡ªå‹•é…ç½®çš„æœ¬åœ°è·¯å¾‘ï¼Œç”¨ä¾†å­˜æ”¾å¾ S3 ä¸‹è¼‰çš„è¨“ç·´æ•¸æ“šï¼Œä»¥ç¢ºä¿è¨“ç·´éç¨‹ä¸­æ¨¡å‹å¯ä»¥é †åˆ©è®€å–æ•¸æ“šã€‚\n",
    "\n",
    "è©³æƒ…è«‹åƒè€ƒï¼š[SageMaker Model Training Storage Paths](https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define the directory to save the datasets\n",
    "save_path = '/opt/ml/input/data/training'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "def save_dataset(file_path, data):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "# Save training data\n",
    "train_file_path = os.path.join(save_path, 'train_dataset.json')\n",
    "save_dataset(train_file_path, sagemaker_train_data)\n",
    "\n",
    "# Save test data\n",
    "test_file_path = os.path.join(save_path, 'test_dataset.json')\n",
    "save_dataset(test_file_path, sagemaker_test_data)\n",
    "\n",
    "print(f\"Dataset saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€<font color=orange>**Now, lets Fine-tune our model. ğŸš€**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **é€²è¡Œ Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨é€™å€‹éƒ¨åˆ†ï¼Œæˆ‘å€‘å°‡æ·±å…¥æ¢è¨ç¥ç¶“ç¶²çµ¡çš„ä¸€äº›åŸºæœ¬åŸç†ï¼Œä»¥åŠå¦‚ä½•é€šéèª¿æ•´è¶…åƒæ•¸ä¾†å„ªåŒ–æ¨¡å‹è¨“ç·´ã€‚æˆ‘ä¹Ÿæœƒä»‹ç´¹ QLoRAï¼ˆQuantization-aware Low-Rank Adaptationï¼‰çš„åŸºæœ¬åŸç†ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œè®“æˆ‘å€‘å›é¡§ä¸€äº›é—œéµæ¦‚å¿µï¼š\n",
    "\n",
    "\n",
    "#### ç¥ç¶“ç¶²çµ¡åŸºç¤æ¦‚å¿µ(Neural Network Fundamentals)\n",
    "\n",
    "1. **ç¥ç¶“ç¶²çµ¡**\n",
    "   - æ¨¡ä»¿äººè…¦çµæ§‹çš„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹\n",
    "   - ç”±å¤šå±¤ç¥ç¶“å…ƒçµ„æˆï¼Œé€šéæ¬Šé‡(weight)å’Œæ¿€æ´»å‡½æ•¸(activation function)è™•ç†è¼¸å…¥æ•¸æ“š\n",
    "   - å»£æ³›æ‡‰ç”¨æ–¼åœ–åƒè­˜åˆ¥(image recognition)ã€è‡ªç„¶èªè¨€è™•ç†(NLP)ã€èªéŸ³è­˜åˆ¥(speech recognition)ç­‰é ˜åŸŸ\n",
    "\n",
    "2. **å‰å‘å‚³æ’­ (Forward Propagation)**\n",
    "   - æ•¸æ“šå¾è¼¸å…¥å±¤(input layer)é€šééš±è—å±¤(hidden layer)åˆ°è¼¸å‡ºå±¤(output layer)çš„éç¨‹\n",
    "   - æ¯ä¸€å±¤çš„è¼¸å‡º(output)ä½œç‚ºä¸‹ä¸€å±¤çš„è¼¸å…¥(input)\n",
    "\n",
    "3. **åå‘å‚³æ’­ (Backward Propagation)**\n",
    "   - è¨ˆç®—æå¤±å‡½æ•¸(loss function)å°æ¯å€‹æ¬Šé‡(weight)çš„æ¢¯åº¦(gradient)\n",
    "   - å¾è¼¸å‡ºå±¤(output layer)å‘è¼¸å…¥å±¤(input layer)é€å±¤èª¿æ•´æ¬Šé‡(weight)\n",
    "\n",
    "4. **æ¢¯åº¦ä¸‹é™ (Gradient Descent)**\n",
    "   - å„ªåŒ–ç¥ç¶“ç¶²çµ¡çš„æ ¸å¿ƒç®—æ³•\n",
    "   - é€šéæ²¿æ¢¯åº¦(gradient)çš„åæ–¹å‘(negative direction)èª¿æ•´æ¬Šé‡(weight)ä¾†æœ€å°åŒ–æå¤±å‡½æ•¸(loss function)\n",
    "\n",
    "#### é—œéµè¶…åƒæ•¸(Hyperparameter)\n",
    "\n",
    "5. **æ‰¹é‡å¤§å° (Batch Size)**\n",
    "   - æ¯æ¬¡æ›´æ–°æ¬Šé‡æ™‚ä½¿ç”¨çš„è¨“ç·´æ¨£æœ¬æ•¸\n",
    "   - è¼ƒå¤§çš„æ‰¹é‡å¯ä»¥æé«˜è¨“ç·´ç©©å®šæ€§ï¼Œä½†å¯èƒ½éœ€è¦æ›´å¤šå…§å­˜\n",
    "\n",
    "6. **å­¸ç¿’ç‡ (Learning Rate)**\n",
    "   - æ§åˆ¶æ¯æ¬¡è¿­ä»£(iteration)æ™‚æ¬Šé‡èª¿æ•´çš„å¹…åº¦\n",
    "   - å¤ªå¤§å¯èƒ½å°è‡´ä¸æ”¶æ–‚ï¼Œå¤ªå°å¯èƒ½å°è‡´è¨“ç·´éæ…¢\n",
    "\n",
    "#### é«˜ç´šæŠ€è¡“(Advanced Techniques)\n",
    "\n",
    "7. **é‡åŒ– (Quantization)**\n",
    "   - å°‡æ¨¡å‹åƒæ•¸å¾é«˜ç²¾åº¦è½‰æ›ç‚ºä½ç²¾åº¦\n",
    "   - å¯ä»¥æ¸›å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æ™‚é–“ï¼Œä½†å¯èƒ½ç•¥å¾®é™ä½ç²¾åº¦\n",
    "\n",
    "8. **LoRA (Low-Rank Adaptation)**\n",
    "   - ä¸€ç¨®é«˜æ•ˆçš„æ¨¡å‹å¾®èª¿æŠ€è¡“\n",
    "   - ä¸»è¦åƒæ•¸ï¼š\n",
    "     - alpha: æ§åˆ¶LoRAæ›´æ–°çš„å¼·åº¦\n",
    "     - rank: æ±ºå®šé©é…å™¨çŸ©é™£çš„ç§©ï¼Œå½±éŸ¿æ¨¡å‹è¡¨é”èƒ½åŠ›å’Œè¨ˆç®—æˆæœ¬\n",
    "\n",
    "   - ç·šæ€§ä»£æ•¸ä¸­çš„ rank æ¦‚å¿µï¼š\n",
    "     - åœ¨å¤§å‹ç¥ç¶“ç¶²çµ¡ä¸­ï¼Œæ¬Šé‡æ›´æ–°é€šå¸¸æ¶‰åŠé«˜ç¶­çŸ©é™£\n",
    "     - LoRA å‡è¨­é€™äº›æ›´æ–°å¯ä»¥ç”¨ä½ç§©çŸ©é™£(low rank)ä¾†è¿‘ä¼¼ï¼Œå¾è€Œæ¸›å°‘è¨“ç·´åƒæ•¸æ•¸é‡\n",
    "     - é€šéèª¿æ•´ rank åƒæ•¸ï¼Œå¯ä»¥åœ¨æ¨¡å‹è¤‡é›œåº¦å’Œè¨ˆç®—æ•ˆç‡ä¹‹é–“å–å¾—å¹³è¡¡\n",
    "\n",
    "9. **QLoRA (Quantization-aware Low-Rank Adaptation)**\n",
    "   - çµåˆé‡åŒ–å’Œ LoRA çš„æŠ€è¡“\n",
    "   - å„ªåŒ–æ­¥é©Ÿï¼š\n",
    "     1. å°‡é è¨“ç·´æ¨¡å‹é‡åŒ–å¾Œä¸¦å‡çµ\n",
    "     2. æ·»åŠ å°å‹ã€å¯è¨“ç·´çš„ LoRA é©é…å™¨å±¤\n",
    "     3. åƒ…å¾®èª¿é©é…å™¨å±¤ï¼ŒåŒæ™‚ä½¿ç”¨å‡çµçš„é‡åŒ–æ¨¡å‹ä½œç‚ºä¸Šä¸‹æ–‡\n",
    "   - å„ªé»ï¼šå¤§å¤§æ¸›å°‘å…§å­˜éœ€æ±‚ï¼ŒåŒæ™‚ä¿æŒæ¨¡å‹æ€§èƒ½\n",
    "\n",
    "é€™äº›è¶…åƒæ•¸å’ŒæŠ€è¡“åœ¨è¨“ç·´è…³æœ¬ [run_qlora.py](../scripts/run_qlora.py) ä¸­è¢«ä½¿ç”¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': \"microsoft/Phi-3.5-mini-instruct\",    # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 3,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 2,                 # Number of updates steps to accumulate \n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'fp16': True ,\n",
    "  'learning_rate': 2e-4,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"constant\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run',                         # output directory, where to save assets during training\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **è¨­ç½®è¨“ç·´ä»»å‹™**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = '../scripts',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.p3.2xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **è¨­å®šè¨“ç·´æ•¸æ“šçš„ä½ç½®ï¼Œä¸¦å•Ÿå‹• Hugging Face æ¨¡å‹çš„è¨“ç·´ä»»å‹™**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a data input dictionary with the uploaded S3 URIs\n",
    "data = {\n",
    "    'training': f\"s3://{sess.default_bucket()}/datasets/phi-3.5-mini-instruct/workshop\"\n",
    "}\n",
    "\n",
    "# Start the training job using the provided datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **å°‡ S3 çš„ URI è½‰æ›ç‚ºä¸€å€‹å¯ä»¥ç›´æ¥åœ¨ AWS S3 ç®¡ç†æ§åˆ¶å°ä¸­è¨ªå•çš„ URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.model_data.replace(\"s3://\", \"https://s3.console.aws.amazon.com/s3/buckets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ğŸš€<font color=orange>**Now, lets deploy our model to an endpoint. ğŸš€**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(Optional) Deploy from Model Registry**\n",
    "\n",
    "ä¸‹æ–¹ç‚ºç¤ºç¯„å¦‚ä½•å¾ Model Hub éƒ¨ç½²æ¨¡å‹ï¼Œè‹¥æœ‰éœ€è¦å¯ä»¥åƒè€ƒã€‚\n",
    "\n",
    "> ```{python}\n",
    "> from sagemaker import ModelPackage # https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.ModelPackage\n",
    "> from time import gmtime, strftime\n",
    ">\n",
    "> model_package_arn = \"arn:aws:sagemaker:us-west-2:097724924093:model-package/Demo-SageMaker-Pipeline-Group/3\"\n",
    "> model = ModelPackage(role=role, # https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.ModelPackage\n",
    ">                      model_package_arn=model_package_arn,\n",
    ">                      sagemaker_session=sess)\n",
    "> model.deploy(initial_instance_count=1, instance_type='ml.g5.xlarge', container_startup_health_check_timeout=1000) # https://sagemaker.readthedocs.> io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "> ```"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
